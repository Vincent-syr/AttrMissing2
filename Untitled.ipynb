{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage 1: pre_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:32:28.228638Z",
     "start_time": "2020-08-22T12:32:28.222394Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import json\n",
    "import torch.utils.data.sampler\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import h5py\n",
    "import argparse\n",
    "\n",
    "import configs\n",
    "import backbone\n",
    "from data.datamgr import TransformLoader\n",
    "from data.dataset import SetDataset\n",
    "import data.feature_loader as feat_loader\n",
    "from methods.protonet import ProtoNet\n",
    "from io_utils import model_dict, parse_args, get_resume_file, get_best_file , get_assigned_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:24:21.958370Z",
     "start_time": "2020-08-22T12:24:21.947281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(aux=False, dataset='CUB', method='protonet', model='ResNet10', n_shot=5, num_classes=200, resume=False, save_freq=30, start_epoch=0, stop_epoch=-1, test_n_way=5, train_aug=True, train_n_way=5, warmup=False)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset'     , default='CUB',        help='CUB/miniImagenet/cross/omniglot/cross_char')\n",
    "parser.add_argument('--model'       , default='ResNet10',      help='model: Conv{4|6} / ResNet{10|18|34|50|101}') # 50 and 101 are not used in the paper\n",
    "parser.add_argument('--method'      , default='protonet',   help='baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}') #relationnet_softmax replace L2 norm with softmax to expedite training, maml_approx use first-order approximation in the gradient for efficiency\n",
    "parser.add_argument('--train_n_way' , default=5, type=int,  help='class num to classify for training') #baseline and baseline++ would ignore this parameter\n",
    "parser.add_argument('--test_n_way'  , default=5, type=int,  help='class num to classify for testing (validation) ') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--n_shot'      , default=5, type=int,  help='number of labeled data in each class, same as n_support') #baseline and baseline++ only use this parameter in finetuning\n",
    "parser.add_argument('--train_aug'   , default=True, action='store_true',  help='perform data augmentation or not during training ') #still required for save_features.py and test.py to find the model path correctly\n",
    "\n",
    "parser.add_argument('--aux'   , default=False,  help='use attribute as auxiliary data, multimodal method') \n",
    "\n",
    "parser.add_argument('--num_classes' , default=200, type=int, help='total number of classes in softmax, only used in baseline') #make it larger than the maximum label value in base class\n",
    "parser.add_argument('--save_freq'   , default=30, type=int, help='Save frequency')\n",
    "parser.add_argument('--start_epoch' , default=0, type=int,help ='Starting epoch')\n",
    "parser.add_argument('--stop_epoch'  , default=-1, type=int, help ='Stopping epoch') #for meta-learning methods, each epoch contains 100 episodes. The default epoch number is dataset dependent. See train.py\n",
    "parser.add_argument('--resume'      , action='store_true', help='continue from previous trained model with largest epoch')\n",
    "parser.add_argument('--warmup'      , action='store_true', help='continue from baseline, neglected if resume is true') #\n",
    "params = parser.parse_args([])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:28:12.498294Z",
     "start_time": "2020-08-22T12:28:12.491164Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = params.aux\n",
    "aug = params.train_aug\n",
    "base_file = configs.data_dir[params.dataset] + 'base.json' \n",
    "val_file   = configs.data_dir[params.dataset] + 'val.json' \n",
    "word_dim = 312\n",
    "image_size = 224\n",
    "params.stop_epoch = 400 # This is different as stated in the open-review paper. However, using 400 epoch in baseline actually lead to over-fitting\n",
    "optimization = 'Adam'\n",
    "n_query = max(1, int(16* params.test_n_way/params.train_n_way)) #if test_n_way is smaller than train_n_way, reduce n_query to keep batch size small ,16\n",
    "# print(\"n_query = \", n_query)\n",
    "train_few_shot_params    = dict(n_way = params.train_n_way, n_support = params.n_shot) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:33:50.785576Z",
     "start_time": "2020-08-22T12:33:50.712245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch041-gpu/lib/python3.6/site-packages/torchvision/transforms/transforms.py:563: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ]
    }
   ],
   "source": [
    "# base_datamgr            = SetDataManager(image_size, n_query = n_query, aux=aux,   **train_few_shot_params)        \n",
    "# base_loader             = base_datamgr.get_data_loader( base_file , aug = params.train_aug )\n",
    "trans_loader = TransformLoader(image_size)\n",
    "transform = trans_loader.get_composed_transform(aug)\n",
    "transform\n",
    "dataset = SetDataset(base_file, 21, transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:58:49.798724Z",
     "start_time": "2020-08-22T12:58:48.793629Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([21, 3, 224, 224])\n",
      "torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(len(batch))\n",
    "    a, b = batch\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T06:32:38.762543Z",
     "start_time": "2020-08-23T06:32:38.755938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'111/vvv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['111','vvv']\n",
    "os.path.join(a[0], a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T13:01:23.937687Z",
     "start_time": "2020-08-22T13:01:23.933600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:24:49.363578Z",
     "start_time": "2020-08-22T12:24:44.922931Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "split_list = ['base', 'val']\n",
    "iter_num = 600\n",
    "\n",
    "few_shot_params = dict(n_way = params.test_n_way , n_support = params.n_shot)   # 5 way, 5 shot\n",
    "\n",
    "model           = ProtoNet( model_dict[params.model], **few_shot_params )\n",
    "model = model.cuda()\n",
    "checkpoint_dir = '%s/checkpoints/%s/%s_%s' %(configs.save_dir, params.dataset, params.model, params.method)\n",
    "if params.train_aug:\n",
    "    checkpoint_dir += '_aug'\n",
    "if not params.method in ['baseline', 'baseline++'] :\n",
    "    checkpoint_dir += '_%dway_%dshot' %( params.train_n_way, params.n_shot)\n",
    "\n",
    "# # load  pre-trained-model params\n",
    "# modelfile   = get_best_file(checkpoint_dir)\n",
    "# tmp = torch.load(modelfile)\n",
    "# model.load_state_dict(tmp['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T04:39:34.885870Z",
     "start_time": "2020-08-16T04:39:34.748260Z"
    }
   },
   "outputs": [],
   "source": [
    "novel_file = os.path.join( checkpoint_dir.replace(\"checkpoints\",\"features\"),\n",
    "                          \"base_best.hdf5\") #defaut split = novel, but you can also test base or val classes\n",
    "cl_data_file = feat_loader.init_loader(novel_file)\n",
    "n_way = 5, \n",
    "n_support = 5, \n",
    "n_query = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T07:48:48.047412Z",
     "start_time": "2020-08-16T07:48:47.937597Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = h5py.File(novel_file)   # <KeysViewHDF5 ['all_feats', 'all_labels', 'count']>\n",
    "print(file.keys())\n",
    "feats = file['all_feats']\n",
    "# feats.shape               # 5888, 512\n",
    "labels = file['all_labels']\n",
    "# labels.shape     # (5888,)\n",
    "while np.sum(feats[-1]) == 0:\n",
    "    feats  = np.delete(feats,-1,axis = 0)\n",
    "    labels = np.delete(labels,-1,axis = 0)\n",
    "\n",
    "print(feats.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T07:05:08.195309Z",
     "start_time": "2020-08-17T07:05:08.148589Z"
    }
   },
   "outputs": [],
   "source": [
    "attr_file = 'filelists/CUB/attr_array.npy'\n",
    "attr = np.load(attr_file)\n",
    "attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:38:24.470233Z",
     "start_time": "2020-08-17T08:38:23.504494Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import data.additional_transforms as add_transforms\n",
    "from data.dataset import SimpleDataset, MultiModalDataset, SetDataset, EpisodicBatchSampler, EpisodicMultiModalSampler\n",
    "from abc import abstractmethod\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:38:31.243578Z",
     "start_time": "2020-08-17T08:38:31.166486Z"
    }
   },
   "outputs": [],
   "source": [
    "img_file = 'filelists/CUB/base.json'\n",
    "attr_file = 'filelists/CUB/attr_array.npy'\n",
    "n_way = 5\n",
    "batch_size = 30\n",
    "n_episodes = 100\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(92),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(np.array([0.485, 0.456, 0.406]),\n",
    "                                     np.array([0.229, 0.224, 0.225]))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:38:38.229132Z",
     "start_time": "2020-08-17T08:38:38.102400Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MultiModalDataset(img_file, attr_file, transform)\n",
    "len(dataset)\n",
    "sampler = EpisodicMultiModalSampler(dataset.label, n_way, batch_size, n_episodes)\n",
    "\n",
    "data_loader_params = dict(batch_sampler = sampler,  num_workers = 12, pin_memory = True)       \n",
    "data_loader = torch.utils.data.DataLoader(dataset, **data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:39:51.822301Z",
     "start_time": "2020-08-17T08:39:51.737575Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(sampler))\n",
    "# # sampler.m_ind\n",
    "# len(sampler.m_ind)\n",
    "# for i in sampler:\n",
    "#     print(i.shape)    # torch.Size([150])\n",
    "#     print(i)\n",
    "#     break\n",
    "a = i.view(5, 30)\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:45:52.352690Z",
     "start_time": "2020-08-17T08:45:52.292562Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.zeros([150,224])\n",
    "a = x.view(5, -1, x.shape[-1])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:31:45.113610Z",
     "start_time": "2020-08-17T08:31:20.304519Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (x, _) in enumerate(data_loader, 1):\n",
    "    img_feat, attr_feat = x\n",
    "    print(img_feat.shape)\n",
    "    print(attr_feat.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:26:47.708839Z",
     "start_time": "2020-08-17T08:26:47.653296Z"
    }
   },
   "outputs": [],
   "source": [
    "len(img_feat)\n",
    "img_feat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:27:06.834350Z",
     "start_time": "2020-08-17T08:27:06.768120Z"
    }
   },
   "outputs": [],
   "source": [
    "img_feat[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T09:25:43.906933Z",
     "start_time": "2020-08-17T09:25:43.343323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attr_feat = x[1]\n",
    "attr_feat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T11:26:10.707286Z",
     "start_time": "2020-08-17T11:26:10.604833Z"
    }
   },
   "outputs": [],
   "source": [
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T11:28:43.448740Z",
     "start_time": "2020-08-17T11:28:43.331610Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.zeros([105,3,224,224])\n",
    "# a.shape    torch.Size([105, 3, 224, 224])\n",
    "b = a.view(5, int(a.shape[0]/5), a.shape[1], a.shape[2], a.shape[3])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T12:13:45.206Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "time.sleep(2)\n",
    "end = time.time()\n",
    "print(\"%.2f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage 2: train_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:05:20.772380Z",
     "start_time": "2020-08-18T11:05:20.339887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import json\n",
    "import torch.utils.data.sampler\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import configs\n",
    "import backbone\n",
    "import data.feature_loader as feat_loader\n",
    "from data.datamgr import SetDataManager\n",
    "from data.dataloader_vae import DATA_LOADER as dataloader\n",
    "\n",
    "from methods.protonet import ProtoNet\n",
    "from io_utils import model_dict, parse_args, get_resume_file, get_best_file , get_assigned_file\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:05:23.917501Z",
     "start_time": "2020-08-18T11:05:23.808094Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'features/CUB/ResNet10_protonet_aug_5way_5shot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:07:24.296568Z",
     "start_time": "2020-08-18T11:07:23.866810Z"
    }
   },
   "outputs": [],
   "source": [
    "base_file = os.path.join(checkpoint_dir.replace(\"checkpoints\",\"features\"),  \"base_best.hdf5\")\n",
    "cl_data_file = feat_loader.init_loader(base_file)\n",
    "# dim = cl_data_file.keys()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:10:05.261738Z",
     "start_time": "2020-08-18T11:09:44.192Z"
    }
   },
   "outputs": [],
   "source": [
    "a = cl_data_file.keys()\n",
    "cl_data_file[a[0]].type\n",
    "# len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:14:53.349474Z",
     "start_time": "2020-08-18T11:14:53.038859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of data.dataloader_vae failed: Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/torch041-gpu/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/root/anaconda3/envs/torch041-gpu/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/root/anaconda3/envs/torch041-gpu/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/root/anaconda3/envs/torch041-gpu/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/test/5Mycode/AttrMissing2/data/dataloader_vae.py\", line 28\n",
      "    img_dim =\n",
      "             ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(a)\n",
    "c =cl_data_file[b[0]][0]\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:35:53.206062Z",
     "start_time": "2020-08-17T13:35:52.966226Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(cl_data_file.keys())\n",
    "# len(cl_data_file[4])\n",
    "class_unique = list(cl_data_file.keys())\n",
    "idxes = torch.randperm(len(class_unique))[:5]\n",
    "print(idxes)\n",
    "classes = [class_unique[i] for i in idxes]\n",
    "print(classes)\n",
    "a = [1,3,5]\n",
    "classes[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:31:53.341606Z",
     "start_time": "2020-08-17T13:31:53.240572Z"
    }
   },
   "outputs": [],
   "source": [
    "l = torch.tensor(cl_data_file[0])\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:36:44.105955Z",
     "start_time": "2020-08-17T13:36:43.933053Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = []\n",
    "for c in classes:\n",
    "    l = torch.tensor(cl_data_file[c])\n",
    "    pos = torch.randperm(len(l))[:5]\n",
    "#     print(pos)\n",
    "    feat = l[pos]\n",
    "#     print(feat.shape)\n",
    "    batch.append(feat)\n",
    "    \n",
    "batch = [t.cpu().numpy() for t in batch]   # [tensor --> ndarray]\n",
    "batch_feature = torch.tensor(batch)  # list --> tensorbatch_feature.shape\n",
    "batch_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:42:52.065635Z",
     "start_time": "2020-08-18T05:42:51.931444Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = 'CUB'\n",
    "auxiliary_data_source = 'attribute'\n",
    "attr_file = 'filelists/CUB/attr_array.npy'\n",
    "base_file = 'features/CUB/ResNet10_protonet_aug_5way_5shot/base_best.hdf5'\n",
    "val_file = 'features/CUB/ResNet10_protonet_aug_5way_5shot/val_best.hdf5'\n",
    "n_way = 5\n",
    "k_shot = 5\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:41:08.195650Z",
     "start_time": "2020-08-18T05:41:07.544633Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dataset = dataloader(DATASET, auxiliary_data_source , base_file, attr_file, n_way, k_shot)\n",
    "# val_dataset = dataloader(DATASET, auxiliary_data_source, val_file, attr_file, n_way, k_shot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:45:18.833387Z",
     "start_time": "2020-08-18T05:45:18.712154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 312])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, data_from_modalities = base_dataset.next_batch(batch_size)\n",
    "# label    # [198, 84, 42, 24, 194, 44, 184, 112, 78, 96]\n",
    "img_feat = data_from_modalities[0]\n",
    "attr_feat = data_from_modalities[1]\n",
    "img_feat.shape     # torch.Size([10, 5, 512])\n",
    "attr_feat.shape    # torch.Size([10, 312])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:41:42.868761Z",
     "start_time": "2020-08-18T08:41:42.760473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from methods.vae_proto import Model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:41:07.460136Z",
     "start_time": "2020-08-18T08:41:07.351425Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num_shots': 0,\n",
    "    'device': 'cuda',\n",
    "    'model_specifics': {'cross_reconstruction': True,\n",
    "                       'name': 'CADA',\n",
    "                       'distance': 'wasserstein',\n",
    "                       'warmup': {'beta': {'factor': 0.25,\n",
    "                                           'end_epoch': 93,\n",
    "                                           'start_epoch': 0},\n",
    "                                  'cross_reconstruction': {'factor': 2.37,\n",
    "                                                           'end_epoch': 75,\n",
    "                                                           'start_epoch': 21},\n",
    "                                  'distance': {'factor': 8.13,\n",
    "                                               'end_epoch': 22,\n",
    "                                               'start_epoch': 6}}},\n",
    "\n",
    "    'lr_gen_model': 0.00015,\n",
    "    'generalized': True,\n",
    "    'xyu_samples_per_class': {'SUN': (200, 0, 400, 0),\n",
    "                              'APY': (200, 0, 400, 0),\n",
    "                              'CUB': (200, 0, 400, 0),\n",
    "                              'AWA2': (200, 0, 400, 0),\n",
    "                              'FLO': (200, 0, 400, 0),\n",
    "                              'AWA1': (200, 0, 400, 0)},\n",
    "    'epochs': 100,\n",
    "    'loss': 'l1',\n",
    "    'auxiliary_data_source' : 'attributes',\n",
    "    'lr_cls': 0.001,\n",
    "    'dataset': 'CUB',\n",
    "    'hidden_size_rule': {'resnet_features': (1560, 1660),\n",
    "                        'attributes': (1450, 665),\n",
    "                        'sentences': (1450, 665) },\n",
    "    'latent_size': 64,\n",
    "    'n_batch' : 100,\n",
    "    'batch_size' : 6\n",
    "\n",
    "}\n",
    "hyperparameters['dataset'] = 'CUB'\n",
    "hyperparameters['num_shots']= 5\n",
    "hyperparameters['num_ways'] = 5\n",
    "hyperparameters['generalized']= True\n",
    "hyperparameters['img_dim'] = 512\n",
    "hyperparameters['attr_dim'] = 312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:42:50.303831Z",
     "start_time": "2020-08-18T08:42:50.088708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 0.0174,  0.0015, -0.0042,  ..., -0.0141, -0.0242, -0.0061],\n",
       "           [-0.0244, -0.0015,  0.0248,  ..., -0.0144, -0.0008,  0.0070],\n",
       "           [ 0.0249,  0.0246,  0.0048,  ...,  0.0130,  0.0038, -0.0107],\n",
       "           ...,\n",
       "           [-0.0107, -0.0242,  0.0101,  ...,  0.0067, -0.0214, -0.0218],\n",
       "           [-0.0029, -0.0114, -0.0095,  ...,  0.0020, -0.0029,  0.0121],\n",
       "           [ 0.0212,  0.0193, -0.0167,  ...,  0.0126,  0.0190,  0.0250]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0178,  0.0202,  0.0014,  ...,  0.0120,  0.0060, -0.0210],\n",
       "           [-0.0082, -0.0018, -0.0303,  ..., -0.0109,  0.0006,  0.0133],\n",
       "           [ 0.0179, -0.0257, -0.0158,  ..., -0.0041, -0.0004,  0.0159],\n",
       "           ...,\n",
       "           [-0.0217, -0.0164, -0.0292,  ..., -0.0003,  0.0087, -0.0195],\n",
       "           [ 0.0262, -0.0178, -0.0117,  ..., -0.0279,  0.0099, -0.0169],\n",
       "           [ 0.0010, -0.0073, -0.0141,  ...,  0.0080,  0.0002,  0.0245]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0201, -0.0020, -0.0181,  ...,  0.0161, -0.0177,  0.0067],\n",
       "           [-0.0234, -0.0231,  0.0090,  ..., -0.0226, -0.0004,  0.0257],\n",
       "           [ 0.0006, -0.0019, -0.0215,  ...,  0.0116, -0.0077, -0.0145],\n",
       "           ...,\n",
       "           [ 0.0013,  0.0140,  0.0136,  ..., -0.0089,  0.0145, -0.0182],\n",
       "           [-0.0283,  0.0217,  0.0108,  ...,  0.0161,  0.0258,  0.0095],\n",
       "           [-0.0279, -0.0287,  0.0063,  ..., -0.0016, -0.0235,  0.0117]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0139,  0.0082, -0.0079,  ..., -0.0063, -0.0031, -0.0067],\n",
       "           [-0.0204, -0.0045,  0.0168,  ..., -0.0221,  0.0143,  0.0257],\n",
       "           [ 0.0285, -0.0058, -0.0129,  ...,  0.0092,  0.0018,  0.0158],\n",
       "           ...,\n",
       "           [ 0.0293, -0.0044, -0.0217,  ..., -0.0011,  0.0161,  0.0153],\n",
       "           [-0.0150,  0.0210,  0.0196,  ..., -0.0024,  0.0019,  0.0051],\n",
       "           [-0.0055,  0.0286, -0.0019,  ...,  0.0012, -0.0175, -0.0056]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0231, -0.0203, -0.0114,  ..., -0.0056, -0.0039,  0.0123],\n",
       "           [ 0.0204,  0.0015, -0.0054,  ...,  0.0218, -0.0243, -0.0208],\n",
       "           [ 0.0233, -0.0108, -0.0218,  ...,  0.0225, -0.0233,  0.0115],\n",
       "           ...,\n",
       "           [ 0.0187, -0.0208,  0.0246,  ..., -0.0213, -0.0042, -0.0148],\n",
       "           [-0.0110, -0.0028,  0.0181,  ...,  0.0230, -0.0046, -0.0126],\n",
       "           [ 0.0187,  0.0239, -0.0126,  ...,  0.0126,  0.0230, -0.0010]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0005,  0.0166, -0.0264,  ..., -0.0076,  0.0105, -0.0064],\n",
       "           [ 0.0282, -0.0223, -0.0013,  ...,  0.0095,  0.0238, -0.0029],\n",
       "           [-0.0167,  0.0263, -0.0015,  ..., -0.0061, -0.0243, -0.0237],\n",
       "           ...,\n",
       "           [-0.0212, -0.0271, -0.0123,  ...,  0.0185, -0.0147,  0.0107],\n",
       "           [-0.0240,  0.0230,  0.0028,  ..., -0.0152,  0.0210,  0.0079],\n",
       "           [ 0.0195,  0.0079,  0.0207,  ..., -0.0074, -0.0155,  0.0034]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0155,  0.0259,  0.0163,  ...,  0.0243, -0.0148, -0.0231],\n",
       "           [-0.0257,  0.0156, -0.0285,  ..., -0.0137,  0.0025, -0.0290],\n",
       "           [-0.0079,  0.0067, -0.0062,  ...,  0.0302, -0.0153, -0.0197],\n",
       "           ...,\n",
       "           [ 0.0026, -0.0114,  0.0026,  ...,  0.0031, -0.0222, -0.0248],\n",
       "           [-0.0050,  0.0046,  0.0309,  ..., -0.0281,  0.0084,  0.0258],\n",
       "           [ 0.0013,  0.0252, -0.0143,  ...,  0.0079, -0.0272,  0.0072]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0133, -0.0247, -0.0097,  ..., -0.0089, -0.0136, -0.0061],\n",
       "           [ 0.0241, -0.0291,  0.0154,  ..., -0.0076, -0.0313,  0.0278],\n",
       "           [ 0.0000, -0.0113, -0.0023,  ...,  0.0275,  0.0305,  0.0068],\n",
       "           ...,\n",
       "           [ 0.0272,  0.0260, -0.0231,  ...,  0.0244,  0.0083,  0.0191],\n",
       "           [-0.0080,  0.0262, -0.0288,  ..., -0.0155,  0.0099, -0.0020],\n",
       "           [-0.0173,  0.0205,  0.0161,  ..., -0.0227,  0.0123,  0.0209]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0308, -0.0315,  0.0109,  ...,  0.0102,  0.0412, -0.0199],\n",
       "           [ 0.0173,  0.0220,  0.0242,  ..., -0.0055,  0.0451, -0.0332],\n",
       "           [ 0.0212,  0.0181, -0.0190,  ...,  0.0126,  0.0423,  0.0181],\n",
       "           ...,\n",
       "           [ 0.0015,  0.0064,  0.0452,  ...,  0.0329, -0.0425, -0.0140],\n",
       "           [-0.0382,  0.0312,  0.0199,  ..., -0.0292,  0.0282,  0.0107],\n",
       "           [-0.0218, -0.0274,  0.0366,  ..., -0.0204,  0.0433,  0.0189]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0254,  0.0308, -0.0159,  ...,  0.0143,  0.0246, -0.0250],\n",
       "           [-0.0115, -0.0102, -0.0322,  ..., -0.0115,  0.0389,  0.0320],\n",
       "           [ 0.0370,  0.0290, -0.0044,  ...,  0.0152, -0.0270, -0.0389],\n",
       "           ...,\n",
       "           [ 0.0104,  0.0386,  0.0378,  ...,  0.0281, -0.0052, -0.0369],\n",
       "           [-0.0202, -0.0154,  0.0374,  ..., -0.0201, -0.0183,  0.0226],\n",
       "           [ 0.0102, -0.0356,  0.0076,  ..., -0.0304, -0.0026,  0.0002]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.], requires_grad=True)],\n",
       "  'lr': 0.00015,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': True}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model = Model(hyperparameters)\n",
    "gen_model.optimizer.param_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T12:52:36.604469Z",
     "start_time": "2020-08-18T12:52:36.493319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(50)).float().view(5,10)\n",
    "b = torch.unsqueeze(a, 1)   # torch.Size([5, 1, 10])\n",
    "c = b.expand(-1, 5, -1)\n",
    "c.shape   # torch.Size([5, 5, 10])\n",
    "\n",
    "d = c.mean(1)   # torch.Size([5, 10])\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:28:08.851238Z",
     "start_time": "2020-08-19T08:28:08.095020Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.dataloader_vae import DATA_LOADER as dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:33:17.956900Z",
     "start_time": "2020-08-19T08:33:17.889618Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = 'CUB'\n",
    "auxiliary_data_source = 'attribute'\n",
    "# attr_file = 'filelists/CUB/attr_array.npy'\n",
    "d = None\n",
    "novel_file = 'features/CUB/ResNet10_protonet_aug_5way_5shot/novel_best.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:33:49.286467Z",
     "start_time": "2020-08-19T08:33:49.005718Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set = dataloader('CUB', novel_file, d, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:39:36.818867Z",
     "start_time": "2020-08-23T11:39:36.810547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5068, -0.3400, -0.4177,  0.5242,  0.4457, -1.4717,  0.9880,  0.6790,\n",
       "          1.4314, -0.0680, -0.3829,  1.0995,  1.4560,  0.3286,  0.2415, -0.3704,\n",
       "          1.6659, -0.9284,  0.7516, -1.0103,  0.4536, -0.4965,  1.3017,  0.2571,\n",
       "          0.6972,  1.4728, -1.8706, -0.1027,  1.0248, -1.9291,  0.1709, -0.8266,\n",
       "         -0.7895, -0.8248,  1.3236, -0.0826, -0.5323,  0.9933, -1.3680, -1.3834,\n",
       "         -0.7544,  0.5060, -1.9649,  1.7509, -0.5231,  0.8683,  1.2475, -0.0208,\n",
       "         -0.6850,  2.1475, -2.1161, -0.2043,  0.2124,  0.2326,  1.5280, -0.2109,\n",
       "          1.9421,  0.3523,  1.7327, -0.9625, -1.8286,  0.9090,  1.6591,  0.9056],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0051, -1.1417, -1.4763,  0.2433,  0.1223,  0.4940, -0.1825,  1.3123,\n",
       "         -0.5825,  0.0571, -1.5742, -0.6558,  0.6694, -0.0342, -0.3034,  0.5195,\n",
       "          1.3215, -0.1841,  0.0254, -1.2157,  1.0674, -2.4046,  1.0176, -0.3468,\n",
       "          0.4355,  0.6109, -0.9156,  1.9181, -2.0077, -1.1370, -1.4109, -0.1158,\n",
       "          1.5685, -0.2908, -1.8221, -1.3757, -0.5946, -0.8752, -0.8695,  0.6338,\n",
       "          2.6405,  0.4581, -0.2214,  0.6878, -0.6710,  0.7930,  0.4496, -1.4137,\n",
       "          0.0986, -0.0712, -0.3162, -0.3119,  1.1097, -2.0982,  0.4729, -0.8752,\n",
       "         -0.2386, -0.7918, -0.2341,  1.8543,  0.5396, -0.1955,  1.9296,  0.7734],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0452,  0.6680, -0.2878, -1.8428,  0.4133,  1.0512,  0.5861,  1.4600,\n",
       "         -0.0196, -0.9983, -0.2854,  0.6623, -1.4366,  0.5791,  0.7915, -0.0725,\n",
       "         -0.2393,  0.1317,  0.1164, -0.5903, -1.9541, -0.3587,  0.0408,  1.4182,\n",
       "         -1.3364, -1.1185,  1.0053,  1.0956,  1.1877, -0.2978,  0.0677, -0.7916,\n",
       "          1.3475, -0.2270,  1.3149,  0.4606,  1.4581,  0.4983, -1.5250,  0.4921,\n",
       "          1.0191,  0.6104, -0.3593,  0.6830, -0.5494, -1.9948, -0.4021,  0.1203,\n",
       "          0.7665,  0.1343, -1.1864,  1.3650, -0.1302,  0.1376,  0.6912, -1.4706,\n",
       "         -2.1664,  0.7446, -0.4531,  0.0552, -0.0535,  0.3565, -2.1228, -0.4042]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5,64)\n",
    "b = torch.zeros(2, 64)\n",
    "c = torch.tensor([1,3])\n",
    "a[c] = b\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch041-gpu",
   "language": "python",
   "name": "torch041-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "700px",
    "left": "1523px",
    "right": "20px",
    "top": "109px",
    "width": "415px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
